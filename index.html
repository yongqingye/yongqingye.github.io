<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title></title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="2487.4">
  <style type="text/css">
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; -webkit-text-stroke: #000000}
    p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0000e9}
    p.p3 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; -webkit-text-stroke: #000000; min-height: 14.0px}
    span.s1 {font-kerning: none}
    span.s2 {font: 12.0px 'Lucida Grande'; font-kerning: none}
    span.s3 {font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000}
    span.s4 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0000e9}
  </style>
</head>
<body>
<p class="p1"><span class="s1">--- layout: home author_profile: true --- Hello there!<span class="Apple-converted-space"> </span></span></p>
<p class="p1"><span class="s1">My name is Yongqing<span class="Apple-converted-space">  </span>(Anthea) Ye [joŋt</span><span class="s2">ɕʰ</span><span class="s1">iÅ‹ je] (meaning "evergreen foliage"). I am a computational linguist and speech scientist, employing both behavioral and computational methods to explore human phonological knowledge and its intersections with phonetics and performance systems.<span class="Apple-converted-space"> </span></span></p>
<p class="p1"><span class="s1">I work with both experimental and corpus data. My current research focuses on developing formal models to investigate the temporal dynamics of vowel nasalization perception. Specifically, I have been training acoustic models with data from a range of languages with varying nasalization patterns, including Hindi and Contemporary American English. I build Bayesian (comparative) and hypothesis-testing perceptual models to explore the mechanisms of perception and how different sources of knowledge, such as acoustic cues, phoneme likelihood, and underspecification, influence listeners' decision-making during vowel nasalization. The goal is to create explicit computational models of the acoustic/auditory processes involved in perception and the perceptual computations applied to these acoustic models, allowing us to clearly define, articulate, and evaluate the assumptions, decisions, and predictions that shape our phonological and perceptual theories.<span class="Apple-converted-space"> </span></span></p>
<p class="p2"><span class="s3">I received my PhD in May 2025 from the <a href="https://lilac.msu.edu/"><span class="s4">Department of Linguistics, Languages and Cultures</span></a> at Michigan State University. My main advisor is <a href="https://karthikdurvasula.gitlab.io/"><span class="s4">Karthik Durvasula</span></a>. I am also advised by <a href="https://betsysneller.github.io/"><span class="s4">Betsy Sneller</span></a>, <a href="https://wagnersu.msu.domains/"><span class="s4">Suzanne Wagner</span></a>, <a href="https://bongiov8.msu.domains/index.html"><span class="s4">Silvina Bongiovanni</span></a> and <a href="https://liny.msu.domains/"><span class="s4">Yen-Hwei Lin</span></a>.<span class="Apple-converted-space"> </span></span></p>
<p class="p3"><span class="s1"></span><br></p>
<p class="p1"><span class="s1">When I’m not doing linguistics, I enjoy hiking, rock climbing, archery, and attending Renaissance Fairs.</span></p>
</body>
</html>
